# README.md

# ğŸ§  Nogn: Turn any room into a game

**Author:** Shant Donabedian | w0899687@student.hccs.edu

**Due Dates:** Midterm â€“ Oct 30 | Final â€“ Dec 4

---

## ğŸ’ Project Tier

**Tier:** 3

**Difficulty:** â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸

**Time:** Very significant

**Resources:** Creative use of free datasets + commodity hardware

**Why Tier 3:** Realâ€‘time multiâ€‘object tracking, projector calibration, and onâ€‘edge deployment hurdles.

---

## ğŸ¤·ğŸ» Problem Statement

Kids need physical play and social interaction. Parents want less â€œgluedâ€‘toâ€‘glassâ€ time without losing the magic of interactive worlds. Current AR systems either require headsets (friction) or screens (sedentary), leaving a gap for roomâ€‘scale, handsâ€‘free play.

---

## ğŸ§© Solution Overview

**Nogn** is a projectionâ€‘mapped playground. A camera watches the floor/walls; computer vision detects players, props, or markers; a projector draws the game world directly onto the room. Think airâ€‘hockey lines, lily pads, enemy zones, scoreboardsâ€”no goggles, no controllers.

Core loop: **see â†’ understand â†’ project â†’ react** within a tight latency budget so actions feel instant.

---

## âš™ï¸ Technical Approach

**Perception**
- **CV Technique:** Realâ€‘time object detection (players/balls/handâ€‘held props) + IDâ€‘consistent multiâ€‘object tracking. ArUco markers for absolute reference and homography.
- **Model:** Ultralytics **YOLOv11â€‘nano** (quantized) for detection; **ByteTrack** for MOT; **ArUco** for calibration.
- **Frameworks:** PyTorch + Ultralytics, OpenCV (ArUco, homography), HailoRT SDK.
- **Why this approach:** YOLOv11â€‘nano is small and fast; ByteTrack preserves identities without heavy reâ€‘ID models; ArUco yields robust projectorâ†”ï¸camera alignment.

**Projection & Calibration**
- Single DLP pico projector (DLPDLCR230NPEVM).
- Printed ArUco board and 4â€‘point interactive calibration to compute **cameraâ†’projector** homography.
- Continuous drift correction by reâ€‘observing fixed room markers.

**Runtime Targets**
- Endâ€‘toâ€‘end latency (cameraâ†’projector): **â‰¤ 50 ms** at 720p.
- Spatial projection error: **â‰¤ 1.5 cm** at center, **â‰¤ 3 cm** at edges after correction.

**Deliverables**
- `notebooks/04_demo.ipynb` â€” inference + visualization walkthrough
- `src/nogn/runtime.py` â€” realâ€‘time loop (capture â†’ detect/track â†’ project)
- `calibration/` â€” printable ArUco board + scripts

| Component | Choice |
| --- | --- |
| Detector | YOLOv11â€‘nano (Ultralytics) |
| Tracker | ByteTrack |
| Markers | ArUco (OpenCV) |
| Framework | PyTorch, OpenCV |
| Accelerator | Raspberry Pi **AI HAT+** (Hailo, 26 TOPS) |
| Output | Realâ€‘time projection + notebook demo |

---

## ğŸ“Š Dataset

- **Strategy:** Start **zeroâ€‘shot** with common classes (person/ball). For game props (custom tokens), collect a **small, focused dataset**: ~**800â€“1200 images** from the target room at multiple lighting angles.
- **Acquisition:** Phone video â†’ frame extraction at 5â€“10 fps; staged poses of props; optionally synthetic renders for rare views.
- **Labeling:** Roboflow or CVAT. Split **70/20/10** (train/val/test). Export **YOLO** format with `data.yaml`.
- **Augmentations:** Random brightness/contrast, blur, small perspective warps; avoid heavy crops that harm projection alignment.

---

## ğŸ† Success Metrics

**Primary**
- **mAP50** (props + ball + player feet) â‰¥ **0.80** on heldâ€‘out test set.

**Secondary (experience)**
- **Latency** â‰¤ **50 ms** cameraâ†’projector pipeline.
- **Tracking stability:** **ID switches < 1 per 30 s** of play with 2â€“3 actors.
- **Projection error:** median **â‰¤ 1.5 cm** at center.

Pass/fail for playability: children can complete a 60â€‘second miniâ€‘game without missed hits due to system lag or drift.

---

## ğŸ“… Weekâ€‘byâ€‘Week Plan

| Week | Task | Deliverable |
| --- | --- | --- |
| 9 | Planning & hardware mounts | Repo scaffold, projector/camera mounted |
| 10 | Midterm proposal | Slides + updated README |
| 11 | Data collection & labeling | v1 dataset + `data.yaml` |
| 12 | Model training & export | Weights + Hailoâ€‘compiled artifact |
| 13 | Runtime + calibration | Realâ€‘time loop + drift correction |
| 14 | Game polish | 2 miniâ€‘games (targets, zones) + video |
| 15 | Presentation | Live demo + final submission |

---

## ğŸ’¸ Resources Needed

**Compute:** Raspberry Pi 5 + Raspberry Pi **AI HAT+** accelerator (Hailo).

**Optics:** **TI DLPDLCR230NPEVM** pico projector (~100 lm), **Raspberry Pi Camera Module 3**.

**Power (projector):** 5 VDC â‰¥ 4 A via 5.5Ã—2.5 mm barrel (separate PSU).

**Mounting:** Simple ceiling/boom mount + printable ArUco board.

**APIs/Libraries:** Ultralytics, OpenCV, HailoRT, NumPy, PyTorch.

**Budget:** $$â€“$$$ (projector already purchased).

**Hardware Source of Truth:** Notion â†’ *Nogn Midterm Project â†’ Inventory/Hardware*.

---

## ğŸ˜ˆ Risks & Mitigation

| Risk | Probability | Impact | Mitigation |
| --- | --- | --- | --- |
| Low light / motion blur | M | H | Faster shutter + more light; denoise; 720p@60fps |
| Calibration drift over time | M | M | Persistent ArUco anchors; periodic autoâ€‘recal |
| Occlusion between players & props | M | M | Tracker with motion model; larger markers; game rules minimizing overlap |
| Hailo compile/ops incompatibility | L | M | Keep to supported ops; export via ONNX; have CPU fallback |
| Projector keystone distortion edges | M | M | Overâ€‘sample border; perâ€‘cell warp grid |
| Latency spikes on Pi I/O | M | M | Preâ€‘allocate buffers; pin threads; reduce copies |

---

## ğŸš€ Getting Started

**1) Setup**

```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

**2) Calibrate**

```bash
python -m nogn.calibrate --print-boardpython -m nogn.calibrate --capturepython -m nogn.calibrate --solve --save ./calibration/homography.json
```

**3) Run demo**

```bash
python -m nogn.runtime \\
  --weights ./models/yolo11n.onnx \\
  --cal ./calibration/homography.json \\
  --camera rpicam

```

---

## ğŸ§  AI Usage Log (Summary)

Document all AI assistance in `/docs/AI_usage_log.md` â€” target **5â€“10 entries** describing prompts, outputs, and edits.

---

## ğŸ§¿ Current Status

- [x]  Repository created
- [x]  Proposal written
- [ ]  Dataset acquired
- [ ]  Model training started
- [ ]  Demo created
- [ ]  Final presentation ready

---

## ğŸ§¾ License

MIT License Â© 2025 Shant Donabedian
